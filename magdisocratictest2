import openai
import random
import networkx as nx

openai.api_key = "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"

class Agent:
    def __init__(self, name, persona):
        self.name = name
        self.persona = persona

    def respond(self, input_text):
        system_prompt = (
            "You are a Socratic AI assistant that reasons by asking questions to reach deeper understanding. "
            "You follow Socratic Chain-of-Thought by examining assumptions, alternatives, and implications before answering."
        )
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"{self.persona}\n\nInput: {input_text}"}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"[ERROR: {e}]"

class Moderator:
    def __init__(self, agents):
        self.agents = agents
        self.weights = {a.name: 1.0 for a in agents}

    def moderate(self, input_text):
        results = []
        for a in self.agents:
            out = a.respond(input_text)
            results.append((a.name, out))
        combined = "\n".join(f"{name}: {out}" for name, out in results)
        consensus_prompt = "You are a moderator combining multiple Socratic opinions. Decide the most accurate final answer."
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": consensus_prompt},
                    {"role": "user", "content": combined}
                ],
                temperature=0.3,
                max_tokens=500
            )
            final = response.choices[0].message.content
        except Exception as e:
            final = f"[ERROR: {e}]"
        return final, results

class MAGDi:
    def __init__(self, agents, moderator):
        self.graph = nx.DiGraph()
        self.agents = agents
        self.moderator = moderator
        self.counter = 0
        self.log = []

    def infer(self, prompt):
        final_output, responses = self.moderator.moderate(prompt)
        for agent_name, resp in responses:
            self.graph.add_node(self.counter, agent=agent_name, response=resp)
            self.counter += 1
        self.graph.add_node(self.counter, agent="MODERATOR", response=final_output)
        self.counter += 1
        self.log.append((prompt, final_output, responses))
        return final_output

class Decomposer:
    def __init__(self):
        pass

    def decompose(self, question):
        system_prompt = (
            "You are a Decomposer model trained via Socratic Chain-of-Thought. "
            "Break this complex question into 2 to 4 subproblems in a logical order."
        )
        try:
            result = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                temperature=0.5,
                max_tokens=300
            )
            return result.choices[0].message.content.split('\n')
        except Exception as e:
            return [f"[ERROR: {e}]"]

class Solver:
    def __init__(self):
        pass

    def solve(self, subquestions):
        answers = []
        for q in subquestions:
            try:
                out = openai.ChatCompletion.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "You are a Socratic AI Problem-Solver who reasons step by step."},
                        {"role": "user", "content": q}
                    ],
                    temperature=0.5,
                    max_tokens=400
                )
                answers.append(out.choices[0].message.content)
            except Exception as e:
                answers.append(f"[ERROR: {e}]")
        combine_prompt = "\n".join(answers) + "\nCombine these answers into a final result."
        try:
            final = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You aggregate partial solutions into a final Socratic answer."},
                    {"role": "user", "content": combine_prompt}
                ],
                temperature=0.5,
                max_tokens=300
            )
            return final.choices[0].message.content
        except Exception as e:
            return f"[ERROR: {e}]"

def split_dataset(data):
    random.shuffle(data)
    n = len(data)
    train = data[:int(0.6*n)]
    val = data[int(0.6*n):int(0.7*n)]
    test = data[int(0.7*n):]
    return train, val, test

def run():
    agents = [
        Agent("Agent1", "Philosopher trained in ethics and logic."),
        Agent("Agent2", "Engineer focused on causality and feasibility."),
        Agent("Agent3", "Historian contextualizing all answers."),
        Agent("Agent4", "Lawyer concerned with legality and precedent."),
        Agent("Agent5", "Economist modeling consequences."),
        Agent("Agent6", "Psychologist modeling human reactions."),
        Agent("Agent7", "Biologist focused on natural systems."),
        Agent("Agent8", "Technologist trained in systems design.")
    ]
    mod = Moderator(agents)
    mag = MAGDi(agents, mod)
    dataset = [
        "Should we deploy AI agents in hospitals without human supervision?",
        "Is universal basic income sustainable in an AI-driven economy?",
        "Can machine learning replace criminal court judges ethically?",
        "Do autonomous drones raise unique legal issues in warfare?",
        "Is AGI development a moral obligation or a threat?"
    ]
    train, val, test = split_dataset(dataset)
    distilled_outputs = []
    for q in train + val:
        distilled_outputs.append((q, mag.infer(q)))
    decomp = Decomposer()
    solve = Solver()
    student_data = test
    student_train = student_data[:int(0.8*len(student_data))]
    student_val = student_data[int(0.8*len(student_data)):int(0.9*len(student_data))]
    student_test = student_data[int(0.9*len(student_data)):]
    for q in student_test:
        subqs = decomp.decompose(q)
        final = solve.solve(subqs)
        print("STUDENT ANSWER:", final)

run()
